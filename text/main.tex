\begin{frontmatter}
    \begin{abstract}
   Deep generative models, such as Variational Autoencoders (VAEs), are widely used in autonomous driving for learning compact latent representations of input data. However, like other deep neural networks, VAEs are often regarded as black-box models, making it difficult to interpret why a particular decision was made and which attributes contributed to the prediction. This lack of transparency raises concerns about trust and reliability, particularly in safety-critical applications such as autonomous vehicle decision-making. 
   
   One approach to imprioving model interpretability is through counterfactual explanations, which aim to determine the minimal changes required to alter the model's prediction. Counterfactual Explanations provide human-interpretable insights by identifying which features are most influential in a decision, offering an alternative to traditional feature attribution methods. In this work, I propose a novel introspection technique that leverages a deep generative model (VAE) combined with feature masking strategies to generate counterfactual explanations for black-box classifiers. Our approach modifies input images and latent space representations to determine what meaningful changes would lead to a different classification outcome.
   
   To demonstrate the effectiveness of this approach, experiments are conducted using the CARLA dataset, a widely used simulation environment for autonomous driving research. The proposed method allows for a deeper understanding of classifier decisions by revealing how slight modifications in the input or latent representation affect predictions. This work contributes to the broader goal of enhancing transparency and explainability in deep learning models for autonomous systems, addressing the increasing demand for trustworthy AI in real-world applications.
    \end{abstract}

       
    
    \tableofcontents
    % \chapter*{Acknowledgements} % optional
    % I thank my cat Bubbles!
    % \listoffigures % optional
     \listoftables % optional

         % \begin{symbols}
    %     \symbolentry{$\alpha$}{Learning rate, controls the step size during optimization}
    %     \symbolentry{$\gamma$}{Discount factor in reinforcement learning}
    %     \symbolentry{$\theta$}{Model parameters in a neural network}
    %     \symbolentry{$\pi$}{Policy in reinforcement learning}
    %     % Add more symbols as needed
    % \end{symbols}
    
\end{frontmatter}

\chapter{Introduction} \label{Introduction}
\input{text/Introduction.tex}

\chapter{Background} \label{Background}
\input{text/Background.tex}

\chapter{Methodology} \label{Methodology}
\input{text/Methodology.tex}

\chapter{Evaluation and Results} \label{Evaluation and Results}
\input{text/Evaluation and Results.tex}

\chapter{Related work} \label{Related work}
\input{text/Related work.tex}

\chapter{Conclusion and Future Work} \label{Conclusion and Future Work}
\input{text/Conclusion and Future Work.tex}


% Bibliography
\printbibliography[heading=bibintoc]

% Appendix
% \appendix
% \chapter{My First Appendix}
% \chapter{Definitions} \label{Definitions}
% \input{text/Definitions.tex}