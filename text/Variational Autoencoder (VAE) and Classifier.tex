\section{Variation Autoencoder (VAE)}



\section{Classifier}
\subsection{Classification Performance with VAE vs Traditional Methods}
\begin{table}[htbp]
    \centering
    \caption{Classifier Performance Metrics}
    \label{tab:performance_metrics}
    \begin{tabular}{>{\raggedright\arraybackslash}m{5cm}cccc}
        \hline
        \textbf{Classifier} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
        \hline
        Deep Learning (Latent Classifier) & 89.31\% & 0.90 & 0.97 & 0.94 \\
        Random Forest (Latent Features) & 86.74\% & 0.88 & 0.91 & 0.89 \\
        KNN (Latent Features) & 80.52\% & 0.81 & 0.83 & 0.82 \\
        SVM (Latent Features) & 84.29\% & 0.85 & 0.86 & 0.85 \\
        \hline
    \end{tabular}
\end{table}

\textbf{Observations}

\begin{itemize}
    \item VAE-based classifiers outperform traditional ML models trained on latent features.
    \item Deep Learning classifier using latent vectors achieves the best accuracy.
    \item Random Forest performs well, indicating latent features capture meaningful decision boundaries.
    \item KNN \& SVM perform suboptimally, likely due to latent space complexity.
\end{itemize}




