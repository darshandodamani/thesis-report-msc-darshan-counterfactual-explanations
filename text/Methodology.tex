This chapter describes the methodology used to generate counterfactual explanations using Variational Autoencoders (VAEs) and evaluate different feature masking strategies to enhance interpretability in autonomous driving systems. The methodology consists of multiple stages, including dataset collection, VAE training, classifier training, feature masking, counterfactual explanation generation, and evaluation.

A high-level workflow of the methodology is shown in Figure . The dataset is collected from the CARLA simulator, preprocessed, and used to train a Variational Autoencoder (VAE) for latent space representation. A classifier is trained to distinguish between "STOP", "GO", "RIGHT, and "LEFT" decisions based on input images. Counterfactual explanations are generated by applying different feature masking techniques to alter the image or latent space representation. Finally, the counterfactuals are evaluated using both AI-based quantitative metrics and human evaluation studies.

\section{Dataset Collection, Labeling, and Splitting Process}
The research involved a comprehensive process of collecting, labeling, and splitting the dataset to prepare it for training and evaluation of the models. The process can be broken down into the following stages:

\subsection{Dataset Collection}
The dataset was collected using the CARLA simulator, an advanced open-source platform designed for autonomous driving research. The simulated environment provided a controlled yet realistic setting for capturing diverse driving scenarios. For this study, Town03 and Town07 were selected as the operational environments, ensuring a mix of structured urban roads and more complex, dynamic settings.

A vehicle model Audi A2 was deployed in autopilot mode to autonomously navigate through these environments while capturing RGB images and corresponding control signals. A front-mounted RGB camera sensor was used to record driving scenes with a 125° field of view (FoV) at a resolution of 160×80 pixels. This resolution was selected to maintain a balance between computational efficiency and the retention of essential visual features for learning-based tasks.

In total, approximately 12,000 images were collected under diverse driving conditions, each paired with corresponding control parameters to facilitate supervised learning tasks. The recorded control signals included the steering angle, which ranged from -1 to 1, where -1 represented full left steering, 0 indicated a straight trajectory, and 1 signified full right steering. The throttle value varied between 0 and 1, with 0 denoting no acceleration and 1 indicating maximum throttle input. Similarly, the brake value ranged from 0 to 1, where 0 represented no braking action, and 1 signified full braking force. These control variables, in combination with the visual data, provided a comprehensive representation of the vehicle's navigation behaviour in the simulated environment.

To ensure robust data acquisition, the collection process incorporated multiple verification mechanisms. Real-time logging was employed to track the number of frames successfully saved, skipped, or lost. Additionally, synchronization between the image files and control data was maintained to avoid inconsistencies. The collected dataset serves as the foundation for both 2-class (STOP vs. GO) and 4-class (STOP, GO, LEFT, RIGHT) classification tasks, as detailed in the subsequent labeling process.

\subsection{Dataset Labelling}

For labeling, we processed the collected data to categorize each instance based on the vehicle's control inputs. We used two labeling schemes: a 2-class scheme distinguishing between STOP and GO, and a 4-class scheme further differentiating between STOP, GO, RIGHT, and LEFT. The labeling was based on thresholds for brake, throttle, and steering values. For the 2-class scheme, instances were labeled as STOP if the brake value exceeded a certain threshold, and GO otherwise. In the 4-class scheme, STOP was prioritized, followed by RIGHT and LEFT if the steering value exceeded specific thresholds and the throttle was above a minimal value, with the remainder labeled as GO. This approach ensured a clear classification of driving actions for both binary and multi-class analysis.

\subsection{Dataset Labeling}
After collecting the dataset, it was labeled to prepare it for training and evaluation. The labeling process involved categorizing each instance based on the vehicle's control inputs using the following mathematical criteria:

\textbf{2-Class Labeling Scheme:}
\begin{itemize}
    \item \textbf{STOP}: 
    \begin{equation}
    \text{label} = \text{STOP} \quad \text{if} \quad \text{brake} > \theta_{\text{STOP}}
    \end{equation}
    \item \textbf{GO}: 
    \begin{equation}
    \text{label} = \text{GO} \quad \text{otherwise}
    \end{equation}
\end{itemize}
where $\theta_{\text{STOP}}$ is the threshold for the brake value.

\textbf{4-Class Labeling Scheme:}
\begin{itemize}
    \item \textbf{STOP}: 
    \begin{equation}
    \text{label} = \text{STOP} \quad \text{if} \quad \text{brake} > \theta_{\text{STOP}}
    \end{equation}
    \item \textbf{RIGHT}: 
    \begin{equation}
    \text{label} = \text{RIGHT} \quad \text{if} \quad \text{steering} > \theta_{\text{TURN}} \quad \text{and} \quad \text{throttle} > \epsilon
    \end{equation}
    \item \textbf{LEFT}: 
    \begin{equation}
    \text{label} = \text{LEFT} \quad \text{if} \quad \text{steering} < -\theta_{\text{TURN}} \quad \text{and} \quad \text{throttle} > \epsilon
    \end{equation}
    \item \textbf{GO}: 
    \begin{equation}
    \text{label} = \text{GO} \quad \text{otherwise}
    \end{equation}
\end{itemize}
where $\theta_{\text{STOP}}$ is the threshold for the brake value, $\theta_{\text{TURN}}$ is the threshold for the steering value, and $\epsilon$ is a minimal throttle value (typically set to 0.1).

These criteria were used to ensure a clear classification of driving actions for both binary and multi-class analysis. The thresholds were determined using either a quantile method, where thresholds were dynamically set based on quantiles of the control data, or a fixed method, where thresholds were manually set.

\section{Variational Autoencoder (VAE)} \label{Section Variational Autoencoder (VAE)}
To generate plausible and semantically meaningful counterfactual explanations, we employ a Variational Autoencoder (VAE) as the backbone of our approach. This design is inspired by the Contrastive Explanation Method (CEM) proposed by Dhurandhar et al.~\cite{DBLP:journals/corr/abs-1802-07623}, which uses autoencoders to ensure that explanations remain on the data manifold and are thus realistic to human observers. While CEM focuses on identifying pertinent positives and negatives for simpler datasets like MNIST, our approach extends this principle by operating on more complex image data and introducing structured latent-space and masking strategies. The use of a VAE enables encoding images into a continuous latent space, where targeted feature manipulations can be decoded into visually coherent counterfactual instances. The rationale and alignment with CEM are discussed further in Section~\ref{Related work}.

\subsection{VAE Architecture}  \label{sec: vae_archeticture}

The VAE employs a CNN-based encoder-decoder architecture.
\subsubsection{Encoder: } The encoder consists of four convolutional layers that progressively downsample the input image (160x80 RGB) while increasing the channel depth (3->64->128->256->512). Each convolutional layer, except the third, is followed by Batch Normalization and a LeakyReLU activation function. The output of the final convolutional layer is flattened and passed through a fully connected layer with 1024 units and LeakyReLU activation. This layer then branches into two separate linear layers, outputting the mean ($μ$) and log-variance ($log σ²$) of the latent distribution, which parameterize a Gaussian distribution over the latent space.

\subsubsection{Decoder: } Mirroring the encoder, the decoder begins with two fully connected layers that expand the sampled latent vector. These are followed by four transposed convolutional layers that progressively upsample the representation back to the original image dimensions. LeakyReLU activations are used after each transposed convolutional layer except the last. A final Sigmoid activation function ensures the output pixel values are within the range [0, 1]. Figure [Insert Figure Number of VAE Architecture Diagram] provides a detailed visualization of the encoder and decoder architectures.

\subsection{Variational Autoencoder (VAE) Training}



\subsubsection{Loss Functions} \label{subsubsection: Loss Functions}

\subsection{Evaluating VAE Performance}


\section{Classifier Model for Prediction}

\subsection{Model Selection}
Type of classifier used: CNN, Random forest, SVM etc.

\subsection{Training Setup}
Loss function, optimizer, training/testing dataset split

\subsection{Classifier Performance Evaluation}
Accuracy, precision, recall, F1-score, confusion matrix


\section{Feature Masking Techniques for Counterfactual Generation}
How different masking techniques are used to modify input images and Latent features

\subsection{ Grid-Based Masking}

\subsection{Object Detection-Based Masking (YOLOv5)}

\subsection{LIME on Images}

\subsection{LIME-Based Masking on Latent Features}




\section{Generating Counterfactual Explanations}
Process of modifying inputs to generate counterfactuals.

\subsection{Counterfactual Explanation Generation Pipeline}
Step-by-step process of generating counterfactuals.


\subsection{Example of Counterfactual Generation}
a visual example of an image before and after counterfactual modification.